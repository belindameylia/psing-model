{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 6\u001b[0m col_count \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Input layer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(col_count, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# # Features (attributes) and target (savings product)\n",
    "X = df_encoded.drop('PSI', axis=1).values  # Customer attributes\n",
    "y = df_encoded['PSI'].values  # Target variable (savings product)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the target labels to one-hot encoding\n",
    "y_encoded = to_categorical(y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Artificial Neural Network (ANN)\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer with softmax for classification\n",
    "model.add(Dense(y_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to the class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map numerical class labels back to the original savings product\n",
    "product_mapping = {0: 'Tabungan Anak Muda', 1: 'Tabungan Berjangka', 2: 'Tabungan Medium', 3: 'Tabungan Online', 4: 'Tabungan Pelajar', 5: 'Tabungan Premium', 6: 'Tabungan Regular', 7: 'Tabungan Valas', 8: 'TabunganKu'}\n",
    "predicted_products = [product_mapping[class_idx] for class_idx in predicted_classes]\n",
    "\n",
    "print(\"Predicted Savings Products for Test Data:\", predicted_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 1.0917 - accuracy: 0.4000 - val_loss: 1.0723 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0565 - accuracy: 0.6000 - val_loss: 1.0478 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0228 - accuracy: 0.8000 - val_loss: 1.0236 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9904 - accuracy: 0.8000 - val_loss: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9601 - accuracy: 0.8000 - val_loss: 0.9776 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9300 - accuracy: 0.8000 - val_loss: 0.9557 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8993 - accuracy: 0.8000 - val_loss: 0.9361 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8706 - accuracy: 1.0000 - val_loss: 0.9171 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8404 - accuracy: 1.0000 - val_loss: 0.8997 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8121 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7842 - accuracy: 1.0000 - val_loss: 0.8688 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7563 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7288 - accuracy: 1.0000 - val_loss: 0.8391 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7019 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6758 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6505 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6262 - accuracy: 1.0000 - val_loss: 0.7893 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6028 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5806 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5587 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5372 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5164 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4958 - accuracy: 1.0000 - val_loss: 0.7386 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4755 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4553 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4360 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4169 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3979 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3795 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3613 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3435 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3260 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2922 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2761 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2455 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2039 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1912 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1675 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1272 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7308 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.7398 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7449 - accuracy: 0.5000\n",
      "Model Accuracy: 50.00%\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Predicted Savings Products for Test Data: ['basic_savings', 'premium_savings']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load or create dataset (for example purposes, creating a sample dataframe)\n",
    "# In practice, load your dataset here with pd.read_csv() or similar.\n",
    "\n",
    "# Sample dataset with customer attributes and target (savings product)\n",
    "data = {\n",
    "    'age': [25, 45, 35, 23, 40, 50, 30],\n",
    "    'income': [50000, 80000, 75000, 40000, 120000, 110000, 65000],\n",
    "    'credit_score': [650, 700, 750, 600, 720, 710, 680],\n",
    "    'risk_tolerance': [1, 2, 2, 1, 3, 3, 2],  # 1 = low, 2 = medium, 3 = high\n",
    "    'savings_product': ['basic_savings', 'high_interest', 'high_interest', 'basic_savings', 'premium_savings', 'premium_savings', 'basic_savings']\n",
    "}\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert categorical target variable into numerical values\n",
    "df['savings_product'] = df['savings_product'].map({'basic_savings': 0, 'high_interest': 1, 'premium_savings': 2})\n",
    "\n",
    "# Features (attributes) and target (savings product)\n",
    "X = df.drop('savings_product', axis=1).values  # Customer attributes\n",
    "y = df['savings_product'].values  # Target variable (savings product)\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the target labels to one-hot encoding\n",
    "y_encoded = to_categorical(y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Artificial Neural Network (ANN)\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer with softmax for classification\n",
    "model.add(Dense(y_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to the class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map numerical class labels back to the original savings product\n",
    "product_mapping = {0: 'basic_savings', 1: 'high_interest', 2: 'premium_savings'}\n",
    "predicted_products = [product_mapping[class_idx] for class_idx in predicted_classes]\n",
    "\n",
    "print(\"Predicted Savings Products for Test Data:\", predicted_products)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
