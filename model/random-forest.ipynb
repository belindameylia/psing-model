{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dython.nominal import associations\n",
    "\n",
    "# Read file dataset from CSV\n",
    "data = pd.read_csv(\"../Survei Pengguna Produk Simpanan Individu.csv\")\n",
    "\n",
    "# Data detail\n",
    "print(data.info())\n",
    "print(data.describe(include='all'))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {\n",
    "    \"Timestamp\":\"jejak waktu\",\n",
    "    \"Kami mohon kesediaan Anda untuk menjawab pertanyaan-pertanyaan pada section berikutnya dengan jujur dan sesuai dengan produk simpanan individu yang Anda miliki. Dengan lanjut ke section berikutnya, Anda menyetujui bahwa seluruh data (terkecuali nama dan nomor telepon undian) akan digunakan sebagai bahan penelitian.\":\"perizinan\",\n",
    "    \"Produk simpanan individu apa yang Anda gunakan?\":\"produk\",\n",
    "    \"Nama / Inisial\":\"nama\",\n",
    "    \"Nomor Telepon - GOPAY/OVO/SHOPEEPAY\":\"nomor_telepon\",\n",
    "    \"Umur\":\"umur\",\n",
    "    \"Domisili\":\"domisili\",\n",
    "    \"Gender\":\"gender\",\n",
    "    \"Status Perkawinan\":\"status_perkawinan\",\n",
    "    \"Jumlah Tanggungan\":\"jumlah_tanggungan\",\n",
    "    \"Kegiatan atau pekerjaan saat ini\":\"profesi\",\n",
    "    \"Apa tujuan pengunaan produk simpanan individu yang Anda pilih?\":\"tujuan\",\n",
    "    \"Berapa jumlah rata-rata penghasilan Anda per bulan?\":\"penghasilan\",\n",
    "    \"Seberapa besar rata-rata persentase penghasilan yang Anda tabung?\":\"persentasi_tabungan\",\n",
    "    \"Menurut Anda, apakah produk simpanan individu yang Anda gunakan saat ini memiliki fungsionalitas yang baik?\":\"rate_fungsionalitas\",\n",
    "    \"Menurut Anda, apakah produk simpanan individu yang Anda gunakan memiliki biaya admin yang sesuai dengan fungsi yang Anda dapatkan?\":\"rate_admin\",\n",
    "    \"Menurut Anda, apakah produk simpanan individu yang anda gunakan memiliki limit tabungan yang sesuai dengan kebutuhan Anda?\":\"rate_limit\",\n",
    "    \"Menurut Anda, apakah produk simpanan individu yang Anda gunakan memiliki bunga tabungan yang sesuai dengan keinginan Anda?\":\"rate_bunga\",\n",
    "    \"Menurut Anda, apakah produk simpanan individu yang Anda gunakan saat ini memiliki syarat setoran awal yang memberatkan?\":\"rate_setoran_awal\",\n",
    "    \"Apakah produk simpanan individu yang Anda gunakan sudah sesuai dan cocok dengan kebutuhan, kemampuan, dan keinginan Anda?\":\"rate_kebutuhan\",\n",
    "    \"Apakah ada alasan lain di luar bunga, limit, dan biaya admin yang membuat Anda memutuskan untuk menggunakan produk simpanan individu tersebut?\":\"alasan_lainnya\"\n",
    "    }, \n",
    "            inplace = True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek missing value kolom\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\n ---Visualization---\")\n",
    "\n",
    "# DataFrame untuk menghitung missing values\n",
    "missing_values = pd.DataFrame({\n",
    "    'Attributes': data.columns,  # Nama kolom\n",
    "    'Frequency': data.isnull().sum()  # Jumlah missing values di setiap kolom\n",
    "})\n",
    "\n",
    "# Urutkan berdasarkan jumlah missing value\n",
    "missing_values = missing_values.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Plot visualisasi\n",
    "plt.figure(figsize=(20, 10))  # Ukuran grafik\n",
    "plt.title('Missing Values', fontsize=20, fontweight='bold')  # Judul grafik\n",
    "\n",
    "sns.barplot(\n",
    "    x='Attributes',\n",
    "    y='Frequency',\n",
    "    data=missing_values,\n",
    "    order=missing_values['Attributes']\n",
    ")\n",
    "\n",
    "# Rotasi label untuk kolom agar lebih mudah dibaca\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Tampilkan grafik\n",
    "plt.tight_layout()  # Atur layout agar tidak terpotong\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus data kosong by label\n",
    "data.dropna(subset=['produk'], inplace=True)\n",
    "\n",
    "# Cek missing value\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data sebelum dihapus duplikat:\\n\", data)\n",
    "\n",
    "# Menghapus duplikat\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print(\"\\nData setelah dihapus duplikat:\\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Tabungan Valas & Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"produk\"] != \"Tabungan Valas\"]\n",
    "data = data[data[\"produk\"] != \"Tabungan Optimal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Irrelevant Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = associations(data)\n",
    "corr = correlations['corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tampilin nilai corr mat by label\n",
    "print(corr['produk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_attributes = corr['produk'][corr['produk'] < 0.05].keys()\n",
    "print(\"Kolom yang akan dihapus:\", irrelevant_attributes)\n",
    "\n",
    "# Hapus kolom dengan korelasi < 0.05\n",
    "for item in irrelevant_attributes:\n",
    "    # Hapus kolom dengan nama yang ada di variabel `item`\n",
    "    data.drop([item], axis=1, inplace=True)\n",
    "\n",
    "# Drop kolom alasan lainnya\n",
    "data.drop(\"alasan_lainnya\", axis=1, inplace=True)\n",
    "\n",
    "print(data.columns)\n",
    "data.to_csv(\"../temp/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding & Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#one-hot encoding purpose\n",
    "all_purpose = {'Investasi', 'Simpanan jangka panjang', 'Kegiatan sehari-hari', 'Lainnya'}\n",
    "for purpose in all_purpose:\n",
    "    data[purpose] = data['tujuan'].apply(lambda x:1 if purpose in x else 0)\n",
    " \n",
    "#rename column purpose    \n",
    "data.rename(columns = {\n",
    "    \"Investasi\":\"investasi\",\n",
    "    \"Simpanan jangka panjang\":\"simpanan_jangka_panjang\",\n",
    "    \"Kegiatan sehari-hari\":\"kegiatan_sehari_hari\",\n",
    "    \"Lainnya\":\"tujuan_lainnya\"\n",
    "    }, \n",
    "            inplace = True)\n",
    "data = data.drop('tujuan',axis=1)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "data['produk'] = label_encoder.fit_transform(data['produk'])\n",
    "data['produk'].unique()\n",
    "\n",
    "data['domisili'] = label_encoder.fit_transform(data['domisili'])\n",
    "data['domisili'].unique()\n",
    "\n",
    "data['umur'] = label_encoder.fit_transform(data['umur'])\n",
    "data['umur'].unique()\n",
    "\n",
    "data['gender'] = label_encoder.fit_transform(data['gender'])\n",
    "data['gender'].unique()\n",
    "\n",
    "data['status_perkawinan'] = label_encoder.fit_transform(data['status_perkawinan'])\n",
    "data['status_perkawinan'].unique()\n",
    "\n",
    "data['profesi'] = label_encoder.fit_transform(data['profesi'])\n",
    "data['profesi'].unique()\n",
    "\n",
    "data['penghasilan'] = label_encoder.fit_transform(data['penghasilan'])\n",
    "data['penghasilan'].unique()\n",
    "\n",
    "data['persentasi_tabungan'] = label_encoder.fit_transform(data['persentasi_tabungan'])\n",
    "data['persentasi_tabungan'].unique()\n",
    "\n",
    "data['rate_fungsionalitas'] = label_encoder.fit_transform(data['rate_fungsionalitas'])\n",
    "data['rate_fungsionalitas'].unique()\n",
    "\n",
    "data['rate_admin'] = label_encoder.fit_transform(data['rate_admin'])\n",
    "data['rate_admin'].unique()\n",
    "\n",
    "data['rate_limit'] = label_encoder.fit_transform(data['rate_limit'])\n",
    "data['rate_limit'].unique()\n",
    "\n",
    "data['rate_bunga'] = label_encoder.fit_transform(data['rate_bunga'])\n",
    "data['rate_bunga'].unique()\n",
    "\n",
    "data['rate_setoran_awal'] = label_encoder.fit_transform(data['rate_setoran_awal'])\n",
    "data['rate_setoran_awal'].unique()\n",
    "\n",
    "data['rate_kebutuhan'] = label_encoder.fit_transform(data['rate_kebutuhan'])\n",
    "data['rate_kebutuhan'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Temp Penghitungan Data\n",
    "# class_data = []\n",
    "\n",
    "# # Menampilkan jumlah record per kelas sebelum oversampling\n",
    "# print(\"Jumlah record per kelas sebelum resampling:\")\n",
    "# print(data['produk'].value_counts())\n",
    "\n",
    "# # Membuat list untuk menampung DataFrame hasil upsampling\n",
    "# resampled_dfs = []\n",
    "\n",
    "# # Melakukan upsampling hanya pada kelas yang memiliki jumlah kurang dari 50\n",
    "# for class_label in data['produk'].unique():\n",
    "#     class_data = data[data['produk'] == class_label]\n",
    "    \n",
    "#     # Cek jika jumlah data pada kelas kurang dari 50\n",
    "#     if len(class_data) < 50:\n",
    "#         # resampled_dfs.append(class_data)\n",
    "#         class_data_upsampled = resample(class_data,\n",
    "#                                         replace=True,  # Sampling dengan penggantian\n",
    "#                                         n_samples=100,  # Mengambil sampel sampai mencapai 50\n",
    "#                                         random_state=42)  # Untuk hasil yang konsisten\n",
    "#         resampled_dfs.append(class_data_upsampled)\n",
    "#     else:\n",
    "#         # resampled_dfs.append(class_data)\n",
    "#         if len(class_data) > 100:\n",
    "#             # resampled_dfs.append(class_data)\n",
    "#             class_data_downsampled = resample(class_data,\n",
    "#                                         replace=True,  # Sampling dengan penggantian\n",
    "#                                         n_samples=100,  # Mengambil sampel sampai mencapai 50\n",
    "#                                         random_state=42)  # Untuk hasil yang konsisten\n",
    "#             resampled_dfs.append(class_data_downsampled)\n",
    "#         # Jika jumlah data sudah cukup (>= 50), masukkan data aslinya\n",
    "#         # else:\n",
    "#         #     resampled_dfs.append(class_data)\n",
    "\n",
    "# # Gabungkan kembali semua kelas yang sudah diupsample\n",
    "# data = pd.concat(resampled_dfs)\n",
    "\n",
    "# # Menampilkan jumlah record per kelas setelah oversampling\n",
    "# print(\"\\nJumlah record per kelas setelah resampling:\")\n",
    "# print(data['produk'].value_counts())\n",
    "\n",
    "# # Menampilkan DataFrame yang sudah diupsample\n",
    "# print(\"\\nDataFrame setelah resampling:\")\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data['produk']\n",
    "X = data.drop(['produk'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Inisialisasi model Random Forest dengan jumlah estimators (tree) tertentu\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi dengan data test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)\n",
    "\n",
    "# Get the class with max probability\n",
    "most_compatible_classes = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train = accuracy_score(y_train, model.predict(X_train)) * 100\n",
    "print(f\"Model Accuracy Train: \" + str(accuracy_train))\n",
    "\n",
    "precision_train = precision_score(y_train, model.predict(X_train), average='weighted') * 100\n",
    "print(f\"Model Precision Train: \" + str(precision_train))\n",
    "\n",
    "recall_train = recall_score(y_train, model.predict(X_train), average='weighted') * 100\n",
    "print(f\"Model Recall Train: \" + str(recall_train))\n",
    "\n",
    "f1_train = f1_score(y_train, model.predict(X_train), average='weighted') * 100\n",
    "print(f\"Model F1 Train: \" + str(f1_train))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(f\"Model Accuracy Test: \" + str(accuracy))\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted') * 100\n",
    "print(f\"Model Precision Test: \" + str(precision))\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted') * 100\n",
    "print(f\"Model Recall Test: \" + str(recall))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
    "print(f\"Model F1 Score Test: \" + str(f1))\n",
    "\n",
    "\n",
    "# Show the first 5 samples with their most compatible class\n",
    "for i in range(50):\n",
    "    print(f\"Sample {i+1}: Most Compatible Class = {most_compatible_classes[i]}, Probability = {max(probabilities[i])*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../export_model/model_randomforest.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved as model_randomforest.pkl!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
